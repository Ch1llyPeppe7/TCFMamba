gpu_id: '2'
log_wandb: false
logging:
  level: DEBUG

# mamba4POI settings
hidden_size: 64           # (int) Number of features in the hidden state. 
num_layers: 1                   # (int) Number of Mamba layers.
dropout_prob: 0.2               # (float) Dropout rate.
loss_type: 'CE'                 # (str) Type of loss function. Range in ['BPR', 'CE'].
d_state: 32              # (int) SSM state expansion factor
d_conv: 4                      # (int) Local convolution width
expand: 2                   # (int) Block expansion factor
Term: 'day'

# Save Directory Settings
checkpoint_dir: 'SavedData'
save_dataloaders: True
dataloaders_save_path: ''  
save_dataset: True         
dataset: gowalla
dataset_save_path: 'SavedData/gowalla.pth' 
seed: 42 



#Dataset Settings
USER_ID_FIELD: user_id
ITEM_ID_FIELD: venue_id
TIME_FIELD: timestamp
LABEL_FIELD: label

load_col:
    inter: [user_id, venue_id,timestamp]
    item: [venue_id,latitude, longitude]


LIST_SUFFIX: "_list"
MAX_ITEM_LIST_LENGTH: 128
ITEM_LIST_LENGTH_FIELD: venue_seq_len



Use_CustomDataset: True  
Use_CustomSampler: False
repeatable: True  
NEG_PREFIX: "neg_"

model: Mamba4POI

# training settings
epochs: 50
train_batch_size: 4096
learner: adam
learning_rate: 0.001
eval_step: 1
stopping_step: 4
single_spec: True

# train_neg_sample_args: 
#   distribution: "popularity"
#   alpha: 0.5
#   dynamic: False
#   sample_num: 5
train_neg_sample_args: ~ #CE

eval_args:
  order: TO 
  spilt: 
    RS: [0.7,0.1,0.2]
  gourp_by: user_id
  max_seq_len: 128 
  mode:
    val: full
    test: full



metrics: ['Recall', 'MRR','NDCG','ItemCoverage','AveragePopularity','TailPercentage']
valid_metric: NDCG@10
eval_batch_size: 4096
weight_decay: 0
topk: [1,5,10,20]
tail_ratio: 0.15






